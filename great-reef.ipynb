{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:12:38.868450Z",
     "iopub.status.busy": "2022-01-04T15:12:38.867922Z",
     "iopub.status.idle": "2022-01-04T15:12:41.732561Z",
     "shell.execute_reply": "2022-01-04T15:12:41.731591Z",
     "shell.execute_reply.started": "2022-01-04T15:12:38.868326Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import ast\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import importlib\n",
    "import cv2 \n",
    "\n",
    "from shutil import copyfile\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from PIL import Image\n",
    "from string import Template\n",
    "from IPython.display import display\n",
    "\n",
    "TRAIN_PATH = '/kaggle/input/tensorflow-great-barrier-reef'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:12:41.735008Z",
     "iopub.status.busy": "2022-01-04T15:12:41.734674Z",
     "iopub.status.idle": "2022-01-04T15:13:53.547114Z",
     "shell.execute_reply": "2022-01-04T15:13:53.545874Z",
     "shell.execute_reply.started": "2022-01-04T15:12:41.734950Z"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Megvii-BaseDetection/YOLOX -q\n",
    "\n",
    "%cd YOLOX\n",
    "!pip install -U pip && pip install -r requirements.txt\n",
    "!pip install -v -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:13:53.550040Z",
     "iopub.status.busy": "2022-01-04T15:13:53.549720Z",
     "iopub.status.idle": "2022-01-04T15:14:15.792330Z",
     "shell.execute_reply": "2022-01-04T15:14:15.791120Z",
     "shell.execute_reply.started": "2022-01-04T15:13:53.549992Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:14:15.796470Z",
     "iopub.status.busy": "2022-01-04T15:14:15.796048Z",
     "iopub.status.idle": "2022-01-04T15:14:15.804927Z",
     "shell.execute_reply": "2022-01-04T15:14:15.803475Z",
     "shell.execute_reply.started": "2022-01-04T15:14:15.796422Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bbox(annots):\n",
    "    bboxes = [list(annot.values()) for annot in annots]\n",
    "    return bboxes\n",
    "\n",
    "def get_path(row):\n",
    "    row['image_path'] = f'{TRAIN_PATH}/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:14:15.807158Z",
     "iopub.status.busy": "2022-01-04T15:14:15.806743Z",
     "iopub.status.idle": "2022-01-04T15:14:15.891025Z",
     "shell.execute_reply": "2022-01-04T15:14:15.890018Z",
     "shell.execute_reply.started": "2022-01-04T15:14:15.807099Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/tensorflow-great-barrier-reef/train.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:14:15.893189Z",
     "iopub.status.busy": "2022-01-04T15:14:15.892827Z",
     "iopub.status.idle": "2022-01-04T15:14:20.982999Z",
     "shell.execute_reply": "2022-01-04T15:14:20.981969Z",
     "shell.execute_reply.started": "2022-01-04T15:14:15.893130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Taken only annotated photos\n",
    "df[\"num_bbox\"] = df['annotations'].apply(lambda x: str.count(x, 'x'))\n",
    "df_train = df[df[\"num_bbox\"]>0]\n",
    "\n",
    "#Annotations \n",
    "df_train['annotations'] = df_train['annotations'].progress_apply(lambda x: ast.literal_eval(x))\n",
    "df_train['bboxes'] = df_train.annotations.progress_apply(get_bbox)\n",
    "\n",
    "#Images resolution\n",
    "df_train[\"width\"] = 1280\n",
    "df_train[\"height\"] = 720\n",
    "\n",
    "#Path of images\n",
    "df_train = df_train.progress_apply(get_path, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:14:20.985664Z",
     "iopub.status.busy": "2022-01-04T15:14:20.984513Z",
     "iopub.status.idle": "2022-01-04T15:14:21.027490Z",
     "shell.execute_reply": "2022-01-04T15:14:21.026450Z",
     "shell.execute_reply.started": "2022-01-04T15:14:20.985601Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = GroupKFold(n_splits = 5) \n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_train['fold'] = -1\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df_train, y = df_train.video_id.tolist(), groups=df_train.sequence)):\n",
    "    df_train.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:14:21.031233Z",
     "iopub.status.busy": "2022-01-04T15:14:21.028764Z",
     "iopub.status.idle": "2022-01-04T15:14:24.958996Z",
     "shell.execute_reply": "2022-01-04T15:14:24.957781Z",
     "shell.execute_reply.started": "2022-01-04T15:14:21.031183Z"
    }
   },
   "outputs": [],
   "source": [
    "HOME_DIR = '/kaggle/working/' \n",
    "DATASET_PATH = 'dataset/images'\n",
    "\n",
    "!mkdir {HOME_DIR}dataset\n",
    "!mkdir {HOME_DIR}{DATASET_PATH}\n",
    "!mkdir {HOME_DIR}{DATASET_PATH}/train2017\n",
    "!mkdir {HOME_DIR}{DATASET_PATH}/val2017\n",
    "!mkdir {HOME_DIR}{DATASET_PATH}/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:14:24.962194Z",
     "iopub.status.busy": "2022-01-04T15:14:24.961794Z",
     "iopub.status.idle": "2022-01-04T15:15:25.265082Z",
     "shell.execute_reply": "2022-01-04T15:15:25.264075Z",
     "shell.execute_reply.started": "2022-01-04T15:14:24.962128Z"
    }
   },
   "outputs": [],
   "source": [
    "SELECTED_FOLD = 4\n",
    "\n",
    "for i in tqdm(range(len(df_train))):\n",
    "    row = df_train.loc[i]\n",
    "    if row.fold != SELECTED_FOLD:\n",
    "        copyfile(f'{row.image_path}', f'{HOME_DIR}{DATASET_PATH}/train2017/{row.image_id}.jpg')\n",
    "    else:\n",
    "        copyfile(f'{row.image_path}', f'{HOME_DIR}{DATASET_PATH}/val2017/{row.image_id}.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:25.270128Z",
     "iopub.status.busy": "2022-01-04T15:15:25.269868Z",
     "iopub.status.idle": "2022-01-04T15:15:25.283388Z",
     "shell.execute_reply": "2022-01-04T15:15:25.282157Z",
     "shell.execute_reply.started": "2022-01-04T15:15:25.270091Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Number of training files: {len(os.listdir(f\"{HOME_DIR}{DATASET_PATH}/train2017/\"))}')\n",
    "print(f'Number of validation files: {len(os.listdir(f\"{HOME_DIR}{DATASET_PATH}/val2017/\"))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:25.285616Z",
     "iopub.status.busy": "2022-01-04T15:15:25.284995Z",
     "iopub.status.idle": "2022-01-04T15:15:25.292636Z",
     "shell.execute_reply": "2022-01-04T15:15:25.291118Z",
     "shell.execute_reply.started": "2022-01-04T15:15:25.285567Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_annot_json(json_annotation, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        output_json = json.dumps(json_annotation)\n",
    "        f.write(output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:25.295160Z",
     "iopub.status.busy": "2022-01-04T15:15:25.294788Z",
     "iopub.status.idle": "2022-01-04T15:15:25.304962Z",
     "shell.execute_reply": "2022-01-04T15:15:25.303958Z",
     "shell.execute_reply.started": "2022-01-04T15:15:25.295115Z"
    }
   },
   "outputs": [],
   "source": [
    "annotion_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:25.307649Z",
     "iopub.status.busy": "2022-01-04T15:15:25.306983Z",
     "iopub.status.idle": "2022-01-04T15:15:25.323969Z",
     "shell.execute_reply": "2022-01-04T15:15:25.322569Z",
     "shell.execute_reply.started": "2022-01-04T15:15:25.307603Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataset2coco(df, dest_path):\n",
    "    \n",
    "    global annotion_id\n",
    "    \n",
    "    annotations_json = {\n",
    "        \"info\": [],\n",
    "        \"licenses\": [],\n",
    "        \"categories\": [],\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    \n",
    "    info = {\n",
    "        \"year\": \"2021\",\n",
    "        \"version\": \"1\",\n",
    "        \"description\": \"COTS dataset - COCO format\",\n",
    "        \"contributor\": \"\",\n",
    "        \"url\": \"https://kaggle.com\",\n",
    "        \"date_created\": \"2021-11-30T15:01:26+00:00\"\n",
    "    }\n",
    "    annotations_json[\"info\"].append(info)\n",
    "    \n",
    "    lic = {\n",
    "            \"id\": 1,\n",
    "            \"url\": \"\",\n",
    "            \"name\": \"Unknown\"\n",
    "        }\n",
    "    annotations_json[\"licenses\"].append(lic)\n",
    "\n",
    "    classes = {\"id\": 0, \"name\": \"starfish\", \"supercategory\": \"none\"}\n",
    "\n",
    "    annotations_json[\"categories\"].append(classes)\n",
    "\n",
    "    \n",
    "    for ann_row in df.itertuples():\n",
    "            \n",
    "        images = {\n",
    "            \"id\": ann_row[0],\n",
    "            \"license\": 1,\n",
    "            \"file_name\": ann_row.image_id + '.jpg',\n",
    "            \"height\": ann_row.height,\n",
    "            \"width\": ann_row.width,\n",
    "            \"date_captured\": \"2021-11-30T15:01:26+00:00\"\n",
    "        }\n",
    "        \n",
    "        annotations_json[\"images\"].append(images)\n",
    "        \n",
    "        bbox_list = ann_row.bboxes\n",
    "        \n",
    "        for bbox in bbox_list:\n",
    "            b_width = bbox[2]\n",
    "            b_height = bbox[3]\n",
    "            \n",
    "            # some boxes in COTS are outside the image height and width\n",
    "            if (bbox[0] + bbox[2] > 1280):\n",
    "                b_width = bbox[0] - 1280 \n",
    "            if (bbox[1] + bbox[3] > 720):\n",
    "                b_height = bbox[1] - 720 \n",
    "                \n",
    "            image_annotations = {\n",
    "                \"id\": annotion_id,\n",
    "                \"image_id\": ann_row[0],\n",
    "                \"category_id\": 0,\n",
    "                \"bbox\": [bbox[0], bbox[1], b_width, b_height],\n",
    "                \"area\": bbox[2] * bbox[3],\n",
    "                \"segmentation\": [],\n",
    "                \"iscrowd\": 0\n",
    "            }\n",
    "            \n",
    "            annotion_id += 1\n",
    "            annotations_json[\"annotations\"].append(image_annotations)\n",
    "        \n",
    "        \n",
    "    print(f\"Dataset COTS annotation to COCO json format completed! Files: {len(df)}\")\n",
    "    return annotations_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:25.326695Z",
     "iopub.status.busy": "2022-01-04T15:15:25.326179Z",
     "iopub.status.idle": "2022-01-04T15:15:25.449662Z",
     "shell.execute_reply": "2022-01-04T15:15:25.448613Z",
     "shell.execute_reply.started": "2022-01-04T15:15:25.326648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converting the COTS dataset to JSON COCO\n",
    "train_annot_json = dataset2coco(df_train[df_train.fold != SELECTED_FOLD], f\"{HOME_DIR}{DATASET_PATH}/train2017/\")\n",
    "val_annot_json = dataset2coco(df_train[df_train.fold == SELECTED_FOLD], f\"{HOME_DIR}{DATASET_PATH}/val2017/\")\n",
    "\n",
    "# Saveing the converted annotations\n",
    "save_annot_json(train_annot_json, f\"{HOME_DIR}{DATASET_PATH}/annotations/train.json\")\n",
    "save_annot_json(val_annot_json, f\"{HOME_DIR}{DATASET_PATH}/annotations/valid.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:25.451938Z",
     "iopub.status.busy": "2022-01-04T15:15:25.451200Z",
     "iopub.status.idle": "2022-01-04T15:15:25.457389Z",
     "shell.execute_reply": "2022-01-04T15:15:25.456088Z",
     "shell.execute_reply.started": "2022-01-04T15:15:25.451891Z"
    }
   },
   "outputs": [],
   "source": [
    "NANO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:25.460343Z",
     "iopub.status.busy": "2022-01-04T15:15:25.459150Z",
     "iopub.status.idle": "2022-01-04T15:15:25.470392Z",
     "shell.execute_reply": "2022-01-04T15:15:25.469377Z",
     "shell.execute_reply.started": "2022-01-04T15:15:25.460291Z"
    }
   },
   "outputs": [],
   "source": [
    "# # selecting file parameters from oryginal github repo for YOLOX-s and YOLOX-nano.\n",
    "config_file_template = '''\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-\n",
    "# Copyright (c) Megvii, Inc. and its affiliates.\n",
    "\n",
    "import os\n",
    "\n",
    "from yolox.exp import Exp as MyExp\n",
    "\n",
    "\n",
    "class Exp(MyExp):\n",
    "    def __init__(self):\n",
    "        super(Exp, self).__init__()\n",
    "        self.depth = 0.33\n",
    "        self.width = 0.50\n",
    "        self.exp_name = os.path.split(os.path.realpath(__file__))[1].split(\".\")[0]\n",
    "        \n",
    "        # Define yourself dataset path\n",
    "        self.data_dir = \"/kaggle/working/dataset/images\"\n",
    "        self.train_ann = \"train.json\"\n",
    "        self.val_ann = \"valid.json\"\n",
    "\n",
    "        self.num_classes = 1\n",
    "\n",
    "        self.max_epoch = $max_epoch\n",
    "        self.data_num_workers = 2\n",
    "        self.eval_interval = 1\n",
    "        \n",
    "        self.mosaic_prob = 1.0\n",
    "        self.mixup_prob = 1.0\n",
    "        self.hsv_prob = 1.0\n",
    "        self.flip_prob = 0.5\n",
    "        self.no_aug_epochs = 2\n",
    "        \n",
    "        self.input_size = (960, 960)\n",
    "        self.mosaic_scale = (0.5, 1.5)\n",
    "        self.random_size = (10, 20)\n",
    "        self.test_size = (960, 960)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:25.473197Z",
     "iopub.status.busy": "2022-01-04T15:15:25.472765Z",
     "iopub.status.idle": "2022-01-04T15:15:25.485992Z",
     "shell.execute_reply": "2022-01-04T15:15:25.484564Z",
     "shell.execute_reply.started": "2022-01-04T15:15:25.473137Z"
    }
   },
   "outputs": [],
   "source": [
    "if NANO:\n",
    "    config_file_template = '''\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-\n",
    "# Copyright (c) Megvii, Inc. and its affiliates.\n",
    "\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from yolox.exp import Exp as MyExp\n",
    "\n",
    "\n",
    "class Exp(MyExp):\n",
    "    def __init__(self):\n",
    "        super(Exp, self).__init__()\n",
    "        self.depth = 0.33\n",
    "        self.width = 0.25\n",
    "        self.input_size = (416, 416)\n",
    "        self.mosaic_scale = (0.5, 1.5)\n",
    "        self.random_size = (10, 20)\n",
    "        self.test_size = (416, 416)\n",
    "        self.exp_name = os.path.split(\n",
    "            os.path.realpath(__file__))[1].split(\".\")[0]\n",
    "        self.enable_mixup = False\n",
    "\n",
    "        # Define yourself dataset path\n",
    "        self.data_dir = \"/kaggle/working/dataset/images\"\n",
    "        self.train_ann = \"train.json\"\n",
    "        self.val_ann = \"valid.json\"\n",
    "\n",
    "        self.num_classes = 1\n",
    "\n",
    "        self.max_epoch = $max_epoch\n",
    "        self.data_num_workers = 2\n",
    "        self.eval_interval = 1\n",
    "\n",
    "    def get_model(self, sublinear=False):\n",
    "        def init_yolo(M):\n",
    "            for m in M.modules():\n",
    "                if isinstance(m, nn.BatchNorm2d):\n",
    "                    m.eps = 1e-3\n",
    "                    m.momentum = 0.03\n",
    "\n",
    "        if \"model\" not in self.__dict__:\n",
    "            from yolox.models import YOLOX, YOLOPAFPN, YOLOXHead\n",
    "            in_channels = [256, 512, 1024]\n",
    "            # NANO model use depthwise = True, which is main difference.\n",
    "            backbone = YOLOPAFPN(self.depth,\n",
    "                                 self.width,\n",
    "                                 in_channels=in_channels,\n",
    "                                 depthwise=True)\n",
    "            head = YOLOXHead(self.num_classes,\n",
    "                             self.width,\n",
    "                             in_channels=in_channels,\n",
    "                             depthwise=True)\n",
    "            self.model = YOLOX(backbone, head)\n",
    "\n",
    "        self.model.apply(init_yolo)\n",
    "        self.model.head.initialize_biases(1e-2)\n",
    "        return self.model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:25.488709Z",
     "iopub.status.busy": "2022-01-04T15:15:25.487550Z",
     "iopub.status.idle": "2022-01-04T15:15:25.501432Z",
     "shell.execute_reply": "2022-01-04T15:15:25.500395Z",
     "shell.execute_reply.started": "2022-01-04T15:15:25.488509Z"
    }
   },
   "outputs": [],
   "source": [
    "PIPELINE_CONFIG_PATH='cots_config.py'\n",
    "\n",
    "pipeline = Template(config_file_template).substitute(max_epoch = 20)\n",
    "\n",
    "with open(PIPELINE_CONFIG_PATH, 'w') as f:\n",
    "    f.write(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:25.503811Z",
     "iopub.status.busy": "2022-01-04T15:15:25.503317Z",
     "iopub.status.idle": "2022-01-04T15:15:26.282552Z",
     "shell.execute_reply": "2022-01-04T15:15:26.281254Z",
     "shell.execute_reply.started": "2022-01-04T15:15:25.503763Z"
    }
   },
   "outputs": [],
   "source": [
    "# ./yolox/data/datasets/voc_classes.py\n",
    "\n",
    "voc_cls = '''\n",
    "VOC_CLASSES = (\n",
    "  \"starfish\",\n",
    ")\n",
    "'''\n",
    "with open('./yolox/data/datasets/voc_classes.py', 'w') as f:\n",
    "    f.write(voc_cls)\n",
    "\n",
    "# ./yolox/data/datasets/coco_classes.py\n",
    "\n",
    "coco_cls = '''\n",
    "COCO_CLASSES = (\n",
    "  \"starfish\",\n",
    ")\n",
    "'''\n",
    "with open('./yolox/data/datasets/coco_classes.py', 'w') as f:\n",
    "    f.write(coco_cls)\n",
    "  \n",
    "!more ./yolox/data/datasets/coco_classes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:26.285602Z",
     "iopub.status.busy": "2022-01-04T15:15:26.285205Z",
     "iopub.status.idle": "2022-01-04T15:15:30.274670Z",
     "shell.execute_reply": "2022-01-04T15:15:30.273526Z",
     "shell.execute_reply.started": "2022-01-04T15:15:26.285526Z"
    }
   },
   "outputs": [],
   "source": [
    "sh = 'wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth'\n",
    "MODEL_FILE = 'yolox_s.pth'\n",
    "\n",
    "if NANO:\n",
    "    sh = '''\n",
    "    wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_nano.pth\n",
    "    '''\n",
    "    MODEL_FILE = 'yolox_nano.pth'\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "  file.write(sh)\n",
    "\n",
    "!bash script.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:30.277869Z",
     "iopub.status.busy": "2022-01-04T15:15:30.277194Z",
     "iopub.status.idle": "2022-01-04T15:15:31.044382Z",
     "shell.execute_reply": "2022-01-04T15:15:31.043183Z",
     "shell.execute_reply.started": "2022-01-04T15:15:30.277790Z"
    }
   },
   "outputs": [],
   "source": [
    "!cp ./tools/train.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T15:15:31.047874Z",
     "iopub.status.busy": "2022-01-04T15:15:31.047527Z",
     "iopub.status.idle": "2022-01-04T18:55:46.350020Z",
     "shell.execute_reply": "2022-01-04T18:55:46.348880Z",
     "shell.execute_reply.started": "2022-01-04T15:15:31.047811Z"
    }
   },
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "    -f cots_config.py \\\n",
    "    -d 1 \\\n",
    "    -b 32 \\\n",
    "    --fp16 \\\n",
    "    -o \\\n",
    "    -c {'yolox_s.pth'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T18:55:46.352788Z",
     "iopub.status.busy": "2022-01-04T18:55:46.352421Z",
     "iopub.status.idle": "2022-01-04T18:55:47.195324Z",
     "shell.execute_reply": "2022-01-04T18:55:47.194133Z",
     "shell.execute_reply.started": "2022-01-04T18:55:46.352745Z"
    }
   },
   "outputs": [],
   "source": [
    "%cp ../../input/yolox-kaggle-fix-for-demo-inference/demo.py tools/demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T18:55:47.199947Z",
     "iopub.status.busy": "2022-01-04T18:55:47.198803Z",
     "iopub.status.idle": "2022-01-04T18:55:56.470761Z",
     "shell.execute_reply": "2022-01-04T18:55:56.469366Z",
     "shell.execute_reply.started": "2022-01-04T18:55:47.199910Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_IMAGE_PATH = \"/kaggle/working/dataset/images/val2017/0-4614.jpg\"\n",
    "MODEL_PATH = \"./YOLOX_outputs/cots_config/best_ckpt.pth\"\n",
    "\n",
    "!python tools/demo.py image \\\n",
    "    -f cots_config.py \\\n",
    "    -c {MODEL_PATH} \\\n",
    "    --path {TEST_IMAGE_PATH} \\\n",
    "    --conf 0.1 \\\n",
    "    --nms 0.45 \\\n",
    "    --tsize 960 \\\n",
    "    --save_result \\\n",
    "    --device gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T18:55:56.473946Z",
     "iopub.status.busy": "2022-01-04T18:55:56.473541Z",
     "iopub.status.idle": "2022-01-04T18:55:56.825218Z",
     "shell.execute_reply": "2022-01-04T18:55:56.824146Z",
     "shell.execute_reply.started": "2022-01-04T18:55:56.473897Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_IMAGE_PATH = \"./YOLOX_outputs/cots_config/vis_res/0-4614.jpg\" \n",
    "Image.open(OUTPUT_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T18:55:56.826978Z",
     "iopub.status.busy": "2022-01-04T18:55:56.826691Z",
     "iopub.status.idle": "2022-01-04T18:55:59.286588Z",
     "shell.execute_reply": "2022-01-04T18:55:59.285667Z",
     "shell.execute_reply.started": "2022-01-04T18:55:56.826940Z"
    }
   },
   "outputs": [],
   "source": [
    "from yolox.utils import postprocess\n",
    "from yolox.data.data_augment import ValTransform\n",
    "\n",
    "COCO_CLASSES = (\n",
    "  \"starfish\",\n",
    ")\n",
    "\n",
    "# get YOLOX experiment\n",
    "current_exp = importlib.import_module('cots_config')\n",
    "exp = current_exp.Exp()\n",
    "\n",
    "# set inference parameters\n",
    "test_size = (960, 960)\n",
    "num_classes = 1\n",
    "confthre = 0.1\n",
    "nmsthre = 0.45\n",
    "\n",
    "\n",
    "#YOLOX model\n",
    "model = exp.get_model()\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "#custom trained checkpoint\n",
    "ckpt_file = \"./YOLOX_outputs/cots_config/best_ckpt.pth\"\n",
    "ckpt = torch.load(ckpt_file, map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T18:55:59.288798Z",
     "iopub.status.busy": "2022-01-04T18:55:59.288507Z",
     "iopub.status.idle": "2022-01-04T18:55:59.298830Z",
     "shell.execute_reply": "2022-01-04T18:55:59.297909Z",
     "shell.execute_reply.started": "2022-01-04T18:55:59.288756Z"
    }
   },
   "outputs": [],
   "source": [
    "def yolox_inference(img, model, test_size): \n",
    "    bboxes = []\n",
    "    bbclasses = []\n",
    "    scores = []\n",
    "    \n",
    "    preproc = ValTransform(legacy = False)\n",
    "\n",
    "    tensor_img, _ = preproc(img, None, test_size)\n",
    "    tensor_img = torch.from_numpy(tensor_img).unsqueeze(0)\n",
    "    tensor_img = tensor_img.float()\n",
    "    tensor_img = tensor_img.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tensor_img)\n",
    "        outputs = postprocess(\n",
    "                    outputs, num_classes, confthre,\n",
    "                    nmsthre, class_agnostic=True\n",
    "                )\n",
    "\n",
    "    if outputs[0] is None:\n",
    "        return [], [], []\n",
    "    \n",
    "    outputs = outputs[0].cpu()\n",
    "    bboxes = outputs[:, 0:4]\n",
    "\n",
    "    bboxes /= min(test_size[0] / img.shape[0], test_size[1] / img.shape[1])\n",
    "    bbclasses = outputs[:, 6]\n",
    "    scores = outputs[:, 4] * outputs[:, 5]\n",
    "    \n",
    "    return bboxes, bbclasses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T18:55:59.306057Z",
     "iopub.status.busy": "2022-01-04T18:55:59.305193Z",
     "iopub.status.idle": "2022-01-04T18:55:59.316943Z",
     "shell.execute_reply": "2022-01-04T18:55:59.315930Z",
     "shell.execute_reply.started": "2022-01-04T18:55:59.305997Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_yolox_predictions(img, bboxes, scores, bbclasses, confthre, classes_dict):\n",
    "    for i in range(len(bboxes)):\n",
    "            box = bboxes[i]\n",
    "            cls_id = int(bbclasses[i])\n",
    "            score = scores[i]\n",
    "            if score < confthre:\n",
    "                continue\n",
    "            x0 = int(box[0])\n",
    "            y0 = int(box[1])\n",
    "            x1 = int(box[2])\n",
    "            y1 = int(box[3])\n",
    "\n",
    "            cv2.rectangle(img, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "            cv2.putText(img, '{}:{:.1f}%'.format(classes_dict[cls_id], score * 100), (x0, y0 - 3), cv2.FONT_HERSHEY_PLAIN, 0.8, (0,255,0), thickness = 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T18:55:59.319281Z",
     "iopub.status.busy": "2022-01-04T18:55:59.318927Z",
     "iopub.status.idle": "2022-01-04T18:56:00.450593Z",
     "shell.execute_reply": "2022-01-04T18:56:00.449629Z",
     "shell.execute_reply.started": "2022-01-04T18:55:59.319239Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_IMAGE_PATH = \"/kaggle/working/dataset/images/val2017/0-4614.jpg\"\n",
    "img = cv2.imread(TEST_IMAGE_PATH)\n",
    "\n",
    "#Get predictions\n",
    "bboxes, bbclasses, scores = yolox_inference(img, model, test_size)\n",
    "\n",
    "#Draw predictions\n",
    "out_image = draw_yolox_predictions(img, bboxes, scores, bbclasses, confthre, COCO_CLASSES)\n",
    "\n",
    "# Since we load image using OpenCV we have to convert it \n",
    "out_image = cv2.cvtColor(out_image, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(out_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T18:56:00.452702Z",
     "iopub.status.busy": "2022-01-04T18:56:00.452194Z",
     "iopub.status.idle": "2022-01-04T18:56:00.482742Z",
     "shell.execute_reply": "2022-01-04T18:56:00.481628Z",
     "shell.execute_reply.started": "2022-01-04T18:56:00.452662Z"
    }
   },
   "outputs": [],
   "source": [
    "import greatbarrierreef\n",
    "\n",
    "env = greatbarrierreef.make_env()   # initialize the environment as per the submission reules of the comepetion.\n",
    "iter_test = env.iter_test()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T18:56:00.485069Z",
     "iopub.status.busy": "2022-01-04T18:56:00.484486Z",
     "iopub.status.idle": "2022-01-04T18:56:01.003827Z",
     "shell.execute_reply": "2022-01-04T18:56:01.002608Z",
     "shell.execute_reply.started": "2022-01-04T18:56:00.485002Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_dict = {\n",
    "    'id': [],\n",
    "    'prediction_string': [],\n",
    "}\n",
    "\n",
    "for (image_np, sample_prediction_df) in iter_test:\n",
    " \n",
    "    bboxes, bbclasses, scores = yolox_inference(image_np, model, test_size)\n",
    "    \n",
    "    predictions = []\n",
    "    for i in range(len(bboxes)):\n",
    "        box = bboxes[i]\n",
    "        cls_id = int(bbclasses[i])\n",
    "        score = scores[i]\n",
    "        if score < confthre:\n",
    "            continue\n",
    "        x_min = int(box[0])\n",
    "        y_min = int(box[1])\n",
    "        x_max = int(box[2])\n",
    "        y_max = int(box[3])\n",
    "        \n",
    "        bbox_width = x_max - x_min\n",
    "        bbox_height = y_max - y_min\n",
    "        \n",
    "        predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n",
    "    \n",
    "    prediction_str = ' '.join(predictions)\n",
    "    sample_prediction_df['annotations'] = prediction_str\n",
    "    env.predict(sample_prediction_df)\n",
    "\n",
    "    print('Prediction:', prediction_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T18:56:01.005913Z",
     "iopub.status.busy": "2022-01-04T18:56:01.005564Z",
     "iopub.status.idle": "2022-01-04T18:56:01.027433Z",
     "shell.execute_reply": "2022-01-04T18:56:01.026416Z",
     "shell.execute_reply.started": "2022-01-04T18:56:01.005866Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('submission.csv')\n",
    "sub_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
